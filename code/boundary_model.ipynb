{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import PIL\n",
    "from google.colab import drive\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPool2D, Input, concatenate, Conv2DTranspose\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "seed = random.randint(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "if IMG_SIZE == 256:\n",
    "    path = '\\content\\drive\\My Drive\\parcel_boundaries_dataset\\patched_data\\256'\n",
    "elif IMG_SIZE == 512:\n",
    "    path = '\\content\\drive\\My Drive\\parcel_boundaries_dataset\\patched_data\\512'\n",
    "\n",
    "input_path = os.path.join(path,\"image\")\n",
    "mask_path = os.path.join(path,\"mask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(image_path):\n",
    "    mask_path = tf.strings.regex_replace(image_path, \"image\", \"labels\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"input_resize_patches\", \"mask_resize_patches\")\n",
    "\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels = 1)\n",
    "\n",
    "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "\n",
    "    return {'image' : image, 'segmentation_mask': mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.list_files(input_path + \"*.png\")\n",
    "\n",
    "train_size = 0.8 * train_dataset.cardinality().numpy()\n",
    "\n",
    "validation_size = 0.1 * train_dataset.cardinality().numpy()\n",
    "\n",
    "train_ds = train_dataset.take(train_size)\n",
    "\n",
    "extra = train_dataset.skip(train_size)  \n",
    "\n",
    "val_ds = extra.take(validation_size)\n",
    "\n",
    "test_ds = extra.skip(validation_size)\n",
    "\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "train_ds = train_ds.map(parse_image)\n",
    "\n",
    "test_ds = test_ds.map(parse_image)\n",
    "\n",
    "val_ds = val_ds.map(parse_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "    \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    \n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "    \n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "buffer_size = 1000\n",
    "\n",
    "dataset = {\"train\": train_ds, \"test\": test_ds, \"val\": val_ds}\n",
    "\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=buffer_size, seed=47)\n",
    "dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "dataset['test'] = dataset['test'].map(load_image_test)\n",
    "dataset['test'] = dataset['test'].repeat()\n",
    "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
    "dataset['test'] = dataset['test'].prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_unet(img_shape):\n",
    "    inputs = Input(shape=img_shape)\n",
    "\n",
    "    previous_block_activation = inputs\n",
    "\n",
    "    contraction = {}\n",
    "    for f in [32, 64, 128, 256]:\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(previous_block_activation)\n",
    "        x = Dropout(0.1)(x)\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        contraction[f'conv{f}'] = x\n",
    "        x = MaxPooling2D((2, 2))(x)\n",
    "        previous_block_activation = x\n",
    "\n",
    "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(previous_block_activation)\n",
    "    c5 = Dropout(0.2)(c5)\n",
    "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    previous_block_activation = c5\n",
    "\n",
    "    for f in reversed([32, 64, 128, 256]):\n",
    "        x = Conv2DTranspose(f, (2, 2), strides=(2, 2), padding='same')(previous_block_activation)\n",
    "        x = concatenate([x, contraction[f'conv{f}']])\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
    "        previous_block_activation = x\n",
    "\n",
    "    outputs = Conv2D(255, kernel_size=(1, 1), activation=\"softmax\")(previous_block_activation)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Free up RAM in case the model definition cells were run multiple times\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = seg_unet((IMG_SIZE, IMG_SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.01), loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "length_data = train_ds.cardinality().numpy()\n",
    "\n",
    "length_val = val_ds.cardinality().numpy()\n",
    "\n",
    "STEPS_PER_EPOCH = length_data // BATCH_SIZE\n",
    "VALIDATION_STEPS = length_val // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=dataset['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/\"+\"lr01_e10_bs8.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "loss_age = model_history.history['accuracy']\n",
    "val_loss_age = model_history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(display_list):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
    "    return pred_mask\n",
    "\n",
    "for image, mask in dataset['test'].take(1):\n",
    "        pred_mask = model.predict(image)\n",
    "        display_sample([image[0], mask[0], create_mask(pred_mask[0])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "594cbcb53b7eb24b01ad1ace3292a9583de43e996a12a214afbcf4f5a5715dd8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
