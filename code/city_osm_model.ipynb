{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-t-little/cnn_diss_repo/blob/main/code/city_osm_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Etn_9d6DBOd4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import PIL\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Conv2D, Input, concatenate, Conv2DTranspose, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc6O2Ez9BoA0",
        "outputId": "c4e7bb19-9334-4462-ab30-b0d60b9fb0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "SEED = 5\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# used to mount the data repository to the google colab session\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/dissertation_seg_data'\n",
        "\n",
        "# assigns a location path to both the image and mask of the segementation data\n",
        "image_path = os.path.join(path,\"input_resize_patches/\")\n",
        "mask_path = os.path.join(path,\"mask_resize_patches/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fycO-k-NCpl0"
      },
      "outputs": [],
      "source": [
        "def load_image(image_path):\n",
        "    # open image\n",
        "    image = tf.io.read_file(image_path)\n",
        "    # decodes image into RGB png\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    # changes dtype of image to int\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    # change input path to mask path\n",
        "    mask_path = tf.strings.regex_replace(image_path, \"image\", \"labels\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"input_resize_patches\", \"mask_resize_patches\")\n",
        "    # open mask\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    # decodes mask into grayscale png\n",
        "    mask = tf.image.decode_png(mask, channels = 1)\n",
        "\n",
        "    # 255 - White (Other)\n",
        "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
        "    # 76 - Grey (Building)\n",
        "    mask = tf.where(mask == 76, np.dtype('uint8').type(1), mask)\n",
        "    # 29 - Black (Road)\n",
        "    mask = tf.where(mask == 29, np.dtype('uint8').type(2), mask)\n",
        "    # change anomaly pixels to class 0\n",
        "    mask = tf.where(tf.math.logical_and(tf.math.logical_and(mask != 0, mask != 1), mask != 2), np.dtype('uint8').type(0), mask)\n",
        "\n",
        "    return {'image' : image, 'mask': mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kewq4YgJC-dK"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.list_files(image_path + \"*.png\")\n",
        "\n",
        "# split data into train\n",
        "train_size = 0.8 * dataset.cardinality().numpy()\n",
        "\n",
        "train_ds = dataset.take(train_size)\n",
        "\n",
        "# split data into validation\n",
        "validation_size = 0.1 * dataset.cardinality().numpy()\n",
        "\n",
        "extra = dataset.skip(train_size)  \n",
        "\n",
        "val_ds = extra.take(validation_size)\n",
        "\n",
        "test_ds = extra.skip(validation_size)\n",
        "\n",
        "# parse image/mask for each dataset\n",
        "train_ds = train_ds.map(load_image)\n",
        "\n",
        "test_ds = test_ds.map(load_image)\n",
        "\n",
        "val_ds = val_ds.map(load_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YOzqp2O6EalI"
      },
      "outputs": [],
      "source": [
        "# used to prepare training data\n",
        "def process_image(data_pair):\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        image = tf.image.flip_up_down(data_pair['image'])\n",
        "        mask = tf.image.flip_up_down(data_pair['mask'])\n",
        "    else:\n",
        "        image = data_pair['image']\n",
        "        mask = data_pair['mask']\n",
        "\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "# used to prepare validation and test data\n",
        "def process_image_alt(data_pair):\n",
        "\n",
        "    image = tf.cast(data_pair['image'], tf.float32) / 255.0\n",
        "\n",
        "    return image, data_pair['mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ulOm0-mgFIfI"
      },
      "outputs": [],
      "source": [
        "# initialise hyper-parameters\n",
        "IMG_SIZE = 512\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "# create and batch each dataset\n",
        "data = {\"train\": train_ds, \"test\": test_ds, \"val\": val_ds}\n",
        "\n",
        "data['train'] = data['train'].map(process_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).shuffle(buffer_size=BUFFER_SIZE, seed=SEED).repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "data['val'] = data['val'].map(process_image_alt).repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "data['test'] = data['test'].map(process_image_alt).repeat().batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kZAKQWAag7Q4"
      },
      "outputs": [],
      "source": [
        "# convolutional block used for both encoder and decoder\n",
        "def convolutional_block(previous, filter_size, kernel):\n",
        "        x = Conv2D(filter_size, kernel, activation='relu', kernel_initializer='he_normal', padding='same')(previous)\n",
        "        x = Dropout(0.05)(x)\n",
        "        x = Conv2D(filter_size, kernel, activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "        return x\n",
        "\n",
        "# u-net method\n",
        "def u_net_seg_model(img_shape, n_classes, filter_start):\n",
        "    # input layer with defined shape\n",
        "    input_layer = Input(shape=img_shape)\n",
        "    previous = input_layer\n",
        "\n",
        "    # number of filters defined at each U-Net layer\n",
        "    filter_list = [filter_start, filter_start * 2, filter_start * 4, filter_start * 8]\n",
        "\n",
        "    # create skip connection\n",
        "    skip = []\n",
        "\n",
        "    # iterate through each layer of the encoder block\n",
        "    for filter_size in filter_list:\n",
        "        x = convolutional_block(previous, filter_size, (3,3))\n",
        "        skip.append(x)\n",
        "        x = MaxPooling2D((2, 2))(x)\n",
        "        previous = x\n",
        "\n",
        "    # reverse the skip connection list\n",
        "    skip = list(reversed(skip))\n",
        "\n",
        "    # bridge connection\n",
        "    x = convolutional_block(previous, filter_start * 8, (3,3))\n",
        "    previous = x\n",
        "\n",
        "    # iterate up through each layer of the decoder block\n",
        "    for count,filter_size in enumerate(reversed(filter_list)):\n",
        "        x = Conv2DTranspose(filter_size, (2, 2), strides=(2, 2), padding='same')(previous)\n",
        "        x = concatenate([x, skip[count]], axis = 3)\n",
        "        convolutional_block(x, filter_size, (3,3))\n",
        "        previous = x\n",
        "\n",
        "    # select output activation function depend on whether the output is binary (sigmoid) or multi-class (softmax)\n",
        "    if n_classes == 1:\n",
        "        activation = 'sigmoid'\n",
        "    else:\n",
        "        activation = 'softmax'\n",
        "\n",
        "    # output layer\n",
        "    output_layer = Conv2D(n_classes, kernel_size=(1, 1), activation=activation)(previous)\n",
        "\n",
        "    return Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# create model with selected parameters\n",
        "model = u_net_seg_model((IMG_SIZE, IMG_SIZE, 3), n_classes = 3, filter_start = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "biohFttqi5Dk"
      },
      "outputs": [],
      "source": [
        "# compile model with optimiser, loss and metrics \n",
        "# loss metric needed to reflect the output of the model data - multi_class = categorical crossentropy \n",
        "# sparse is used due to nature of the preprocessing on the ground truth mask\n",
        "model.compile(optimizer=Adam(), loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bE_KXVT0wbed"
      },
      "outputs": [],
      "source": [
        "# callback saving the model each time it achieves a better loss value\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint((\"/content/drive/MyDrive/\"+\"large_epoch_building_roads_model_e100_bs4.h5\"), verbose = 1, save_best_only=True, save_weights_only=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x-0QJN-bjIFi"
      },
      "outputs": [],
      "source": [
        "# calculate number of steps per epoch and validation steps\n",
        "\n",
        "length_data = train_ds.cardinality().numpy()\n",
        "\n",
        "length_val = val_ds.cardinality().numpy()\n",
        "\n",
        "STEPS_PER_EPOCH = length_data // BATCH_SIZE\n",
        "\n",
        "VALIDATION_STEPS = length_val // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "NNiuPXJdjJo-",
        "outputId": "b24a7c1b-f69c-4585-db5f-b091b1333d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.7446 - accuracy: 0.6695\n",
            "Epoch 1: val_loss improved from inf to 0.67557, saving model to /content/drive/MyDrive/large_epoch_building_roads_model_e100_bs4.h5\n",
            "469/469 [==============================] - 1367s 3s/step - loss: 0.7446 - accuracy: 0.6695 - val_loss: 0.6756 - val_accuracy: 0.7093\n",
            "Epoch 2/100\n",
            "469/469 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.7427\n",
            "Epoch 2: val_loss improved from 0.67557 to 0.54194, saving model to /content/drive/MyDrive/large_epoch_building_roads_model_e100_bs4.h5\n",
            "469/469 [==============================] - 553s 1s/step - loss: 0.5973 - accuracy: 0.7427 - val_loss: 0.5419 - val_accuracy: 0.7688\n",
            "Epoch 3/100\n",
            "287/469 [=================>............] - ETA: 2:04 - loss: 0.5347 - accuracy: 0.7720"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-edba3927cf3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the U-Net model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALIDATION_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# run the U-Net model\n",
        "model_history = model.fit(data['train'], epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_data=data['val'], validation_steps=VALIDATION_STEPS, callbacks = callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40PafUTdvQ7I"
      },
      "outputs": [],
      "source": [
        "# model metrics during training\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "accuracy = model_history.history['accuracy']\n",
        "val_accuracy = model_history.history['val_accuracy']\n",
        "\n",
        "# function to plot metrics\n",
        "def plot_training_data(graph_name, train_metric, val_metric):\n",
        "    plt.figure(figsize = (8,8))\n",
        "    plt.plot(train_metric, label = \"Train\")\n",
        "    plt.plot(val_metric, label = \"Validation\")\n",
        "    plt.title(graph_name)\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcDy5TYlNn76"
      },
      "outputs": [],
      "source": [
        "plot_training_data(\"Training and Validation Loss\", loss, val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCLBFQ0YnlX8"
      },
      "outputs": [],
      "source": [
        "plot_training_data(\"Training and Validation Accuracy\", accuracy, val_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfrxq8ZiCpd2"
      },
      "outputs": [],
      "source": [
        "# graph the prediction of an image, ground truth mask and predicted mask\n",
        "def plot_predictions(img,mask,pred_mask):\n",
        "    plt.figure(figsize=(30,30))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(img))\n",
        "    plt.title('Image')\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "    plt.title('Mask')\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask))\n",
        "    plt.title('Predicted Mask')\n",
        "    plt.show()\n",
        "\n",
        "#\n",
        "def format_prediction(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
        "    return pred_mask\n",
        "\n",
        "# randomly select half a batch of images from the data to create a segmentation using the U-Net\n",
        "for image, mask in test_ds.take(1):\n",
        "    for i in range(BATCH_SIZE//2):\n",
        "        pred_mask = model.predict(image)\n",
        "        pred_mask = format_prediction(pred_mask[i])\n",
        "        plot_predictions(image[i], mask[i], pred_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cz8SWmiLMC6"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "594cbcb53b7eb24b01ad1ace3292a9583de43e996a12a214afbcf4f5a5715dd8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
