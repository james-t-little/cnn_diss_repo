{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-t-little/cnn_diss_repo/blob/main/tf_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Etn_9d6DBOd4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import PIL\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc6O2Ez9BoA0",
        "outputId": "10559201-430a-4f92-a26f-8df70c98c558"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/dissertation_seg_data'\n",
        "\n",
        "input_path = os.path.join(path,\"input_resize_patches/\")\n",
        "\n",
        "mask_path = os.path.join(path,\"mask_resize_patches/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2VkFjky4BpTZ"
      },
      "outputs": [],
      "source": [
        "# Image size that we are going to use\n",
        "IMG_SIZE = 512\n",
        "# Our images are RGB (3 channels)\n",
        "N_CHANNELS = 3\n",
        "# Scene Parsing has 150 classes + `not labeled`\n",
        "N_CLASSES = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fycO-k-NCpl0"
      },
      "outputs": [],
      "source": [
        "def parse_image(image_path):\n",
        "    mask_path = tf.strings.regex_replace(image_path, \"image\", \"labels\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"input_resize_patches\", \"mask_resize_patches\")\n",
        "\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels = 1)\n",
        "\n",
        "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
        "\n",
        "    return {'image' : image, 'segmentation_mask': mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kewq4YgJC-dK"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.list_files(input_path + \"*.png\")\n",
        "\n",
        "train_size = 0.8 * train_dataset.cardinality().numpy()\n",
        "\n",
        "validation_size = 0.1 * train_dataset.cardinality().numpy()\n",
        "\n",
        "train_ds = train_dataset.take(train_size)\n",
        "\n",
        "extra = train_dataset.skip(train_size)  \n",
        "\n",
        "val_ds = extra.take(validation_size)\n",
        "\n",
        "test_ds = extra.skip(validation_size)\n",
        "\n",
        "train_dataset = train_dataset.map(parse_image)\n",
        "\n",
        "train_ds = train_ds.map(parse_image)\n",
        "\n",
        "test_ds = test_ds.map(parse_image)\n",
        "\n",
        "val_ds = val_ds.map(parse_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YOzqp2O6EalI"
      },
      "outputs": [],
      "source": [
        "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
        "    \n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    \n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_train(datapoint: dict) -> tuple:\n",
        "    \n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint: dict) -> tuple:\n",
        "\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ulOm0-mgFIfI"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "# for reference about the BUFFER_SIZE in shuffle:\n",
        "# https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = {\"train\": train_ds, \"test\": test_ds, \"val\": val_ds}\n",
        "\n",
        "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=47)\n",
        "dataset['train'] = dataset['train'].repeat()\n",
        "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset['val'] = dataset['val'].map(load_image_test)\n",
        "dataset['val'] = dataset['val'].repeat()\n",
        "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "dataset['test'] = dataset['test'].map(load_image_test)\n",
        "dataset['test'] = dataset['test'].repeat()\n",
        "dataset['test'] = dataset['test'].batch(BATCH_SIZE)\n",
        "dataset['test'] = dataset['test'].prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2lZJMT6_lg06"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras.layers import Conv2D, MaxPool2D, Input, concatenate, Conv2DTranspose\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import VGG16, InceptionV3\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kZAKQWAag7Q4"
      },
      "outputs": [],
      "source": [
        "def unet(img_shape):\n",
        "    inputs = Input(shape=img_shape)\n",
        "\n",
        "    previous_block_activation = inputs\n",
        "\n",
        "    contraction = {}\n",
        "    for f in [32, 64, 128, 256]:\n",
        "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(previous_block_activation)\n",
        "        x = Dropout(0.1)(x)\n",
        "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "        contraction[f'conv{f}'] = x\n",
        "        x = MaxPooling2D((2, 2))(x)\n",
        "        previous_block_activation = x\n",
        "\n",
        "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(previous_block_activation)\n",
        "    c5 = Dropout(0.2)(c5)\n",
        "    c5 = Conv2D(160, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "    previous_block_activation = c5\n",
        "\n",
        "    for f in reversed([32, 64, 128, 256]):\n",
        "        x = Conv2DTranspose(f, (2, 2), strides=(2, 2), padding='same')(previous_block_activation)\n",
        "        x = concatenate([x, contraction[f'conv{f}']])\n",
        "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "        x = Dropout(0.2)(x)\n",
        "        x = Conv2D(f, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "        previous_block_activation = x\n",
        "\n",
        "    outputs = Conv2D(255, kernel_size=(1, 1), activation=\"softmax\")(previous_block_activation)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = unet((IMG_SIZE, IMG_SIZE, N_CHANNELS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "biohFttqi5Dk"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.01), loss = tf.keras.losses.SparseCategoricalCrossentropy(),metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-0QJN-bjIFi",
        "outputId": "b0bf1572-4a55-451e-9870-0b26491712fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "length_data = train_ds.cardinality().numpy()\n",
        "\n",
        "length_val = val_ds.cardinality().numpy()\n",
        "\n",
        "STEPS_PER_EPOCH = length_data // BATCH_SIZE\n",
        "VALIDATION_STEPS = length_val // BATCH_SIZE\n",
        "\n",
        "length_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNiuPXJdjJo-",
        "outputId": "4d9968bf-5807-40c6-f787-34bf6d2582de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "model_history = model.fit(dataset['train'], epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=dataset['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55MWnMSruciA"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/\"+\"lr01_e10_bs8.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40PafUTdvQ7I"
      },
      "outputs": [],
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "loss_age = model_history.history['accuracy']\n",
        "val_loss_age = model_history.history['val_accuracy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfrxq8ZiCpd2"
      },
      "outputs": [],
      "source": [
        "def display_sample(display_list):\n",
        "    \n",
        "    plt.figure(figsize=(18, 18))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def create_mask(pred_mask: tf.Tensor) -> tf.Tensor:\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = tf.expand_dims(pred_mask, axis=-1)\n",
        "    return pred_mask\n",
        "\n",
        "for image, mask in dataset['test'].take(1):\n",
        "        pred_mask = model.predict(image)\n",
        "        display_sample([image[0], mask[0], create_mask(pred_mask[0])])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyPm7OaeSpmQzJEjYtxdP+4/",
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "413c54d42d867d78bc5693b88112002b4b75f03abc9fed1665b973f73c05d110"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
