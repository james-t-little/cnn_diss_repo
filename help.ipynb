{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDUg20OXnaVRQboQeZnHmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/james-t-little/cnn_diss_repo/blob/main/help.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Etn_9d6DBOd4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import PIL\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/dissertation_seg_data'\n",
        "\n",
        "input_path = os.path.join(path,\"input_resize_patches/\")\n",
        "\n",
        "mask_path = os.path.join(path,\"mask_resize_patches/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nc6O2Ez9BoA0",
        "outputId": "428007ff-7608-44e2-9c35-5eaff398286a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image size that we are going to use\n",
        "IMG_SIZE = 512\n",
        "# Our images are RGB (3 channels)\n",
        "N_CHANNELS = 3\n",
        "# Scene Parsing has 150 classes + `not labeled`\n",
        "N_CLASSES = 4"
      ],
      "metadata": {
        "id": "2VkFjky4BpTZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_image(img_path: str) -> dict:\n",
        "    print(img_path)\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "\n",
        "    # mask = tf.io.read_file(mask_path)\n",
        "    # # The masks contain a class index for each pixels\n",
        "    # mask = tf.image.decode_png(mask, channels=1)\n",
        "    # # In scene parsing, \"not labeled\" = 255\n",
        "    # # But it will mess up with our N_CLASS = 150\n",
        "    # # Since 255 means the 255th class\n",
        "    # # Which doesn't exist\n",
        "    # mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
        "    # # Note that we have to convert the new value (0)\n",
        "    # # With the same dtype than the tensor itself\n",
        "\n",
        "    return {'image': image}"
      ],
      "metadata": {
        "id": "fycO-k-NCpl0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path + \"*.png\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wKxzW0CiIiWJ",
        "outputId": "b71ad03a-cd72-4afc-f7a5-3df0efdc5c25"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/dissertation_seg_data/input_resize_patches/*.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.list_files(input_path + \"*.png\")\n",
        "train_dataset = train_dataset.map(parse_image)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kewq4YgJC-dK",
        "outputId": "5e299844-d877-4295-a2ff-2b8993bab543"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"args_0:0\", shape=(), dtype=string)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset element_spec={'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
        "    \n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    \n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_train(datapoint: dict) -> tuple:\n",
        "    \n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "@tf.function\n",
        "def load_image_test(datapoint: dict) -> tuple:\n",
        "\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "YOzqp2O6EalI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}